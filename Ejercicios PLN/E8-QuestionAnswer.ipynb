{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sergiomora03/AdvancedTopicsAnalytics/blob/main/exercises/E7-QuestionAnswer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2NseOxJAIFM"
      },
      "source": [
        "## Question & Answer\n",
        "\n",
        "Creating a Question-Answer Transformer model or QA Transformer can be beneficial for several reasons, particularly in the field of Natural Language Processing (NLP). Here are some compelling reasons why you might want to develop a QA Transformer:\n",
        "\n",
        "1. **Question-Answering Systems:** QA Transformers are designed to provide accurate and contextually relevant answers to questions posed in natural language. These systems have a wide range of practical applications, including chatbots, virtual assistants, customer support, and information retrieval.\n",
        "\n",
        "2. **Information Retrieval:** QA Transformers can be used to search through large corpora of text and extract precise answers to user queries. This can improve the efficiency and effectiveness of information retrieval systems.\n",
        "\n",
        "3. **Document Summarization:** QA Transformers can be used to summarize long documents by answering questions about the document's content. This makes it easier for users to quickly understand the key points and relevant information in a text.\n",
        "\n",
        "4. **Education and E-Learning:** QA Transformers can be integrated into educational platforms to provide instant answers and explanations to students' questions. They can also help with the automatic generation of quiz questions and answers.\n",
        "\n",
        "5. **Content Generation:** QA Transformers can assist in content generation by automatically answering questions based on available knowledge. This can be useful for generating FAQs, product descriptions, and informative articles.\n",
        "\n",
        "6. **Customer Support:** Many companies use QA systems to automate responses to frequently asked questions, freeing up human agents to handle more complex queries and providing customers with quick solutions.\n",
        "\n",
        "7. **Medical Diagnosis:** QA Transformers can assist medical professionals by answering questions related to patient records, medical literature, and diagnostic information, potentially leading to faster and more accurate diagnoses.\n",
        "\n",
        "8. **Legal and Compliance:** In the legal field, QA Transformers can be used to search and extract information from legal documents, assisting lawyers in their research and case preparation.\n",
        "\n",
        "9. **Language Translation:** QA Transformers can be used to answer questions about language translation, helping users understand the meaning of words, phrases, or sentences in different languages.\n",
        "\n",
        "10. **Scientific Research:** QA Transformers can support researchers by answering questions related to scientific literature, allowing them to quickly access relevant information for their studies.\n",
        "\n",
        "11. **Decision Support:** QA Transformers can aid in decision-making processes by providing answers to questions related to data analysis, market research, and business intelligence.\n",
        "\n",
        "12. **Accessibility:** QA Transformers can improve accessibility for individuals with disabilities by providing spoken or written answers to their questions, helping them access information more easily.\n",
        "\n",
        "Overall, QA Transformers have the potential to enhance information retrieval, automation, and user interaction in various domains, making them a valuable tool in the development of intelligent systems and applications. The ability to provide accurate and context-aware answers to questions in natural language is a key advantage of these models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0voj5DTPAukU"
      },
      "source": [
        "---\n",
        "\n",
        "Exercise:\n",
        "\n",
        "Now, as a data scientist expert in NLP, you are asked to create a model to be able to answer question in Spanish. Your stakeholders will pass you an article and one question and your model should answer it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bw-K8uOkAG95",
        "outputId": "9da1870c-45aa-4d54-cddf-4e4632507546"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.11.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.7.22)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install requests beautifulsoup4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hKs-JhtBwzf",
        "outputId": "325593e2-4ee2-4996-d97d-5d37c4441e38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Over the course of February, Geoffrey Hinton, one of the most influential AI researchers of the past 50 years, had a “slow eureka moment.”\n",
            "Hinton, 76, has spent his career trying to build AI systems that model the human brain, mostly in academia before joining Google in 2013. He had always believed that the brain was better than the machines that he and others were building, and that by making them more like the brain, they would improve. But in February, he realized “the digital intelligence we’ve got now may be better than the brain already. It’s just not scaled up quite as big.” \n",
            "Developers around the world are currently racing to build the biggest AI systems that they can. Given the current rate at which AI companies are increasing the size of models, it could be less than five years until AI systems have 100 trillion connections—roughly as many as there are between neurons in the human brain.\n",
            "Alarmed, Hinton left his post as VP and engineering fellow in May and gave a flurry of interviews in which he explained that he had left in order to be able to speak freely on the dangers of AI—and his regrets over helping bring that technology into existence. He worries about what could happen once AI systems are scaled up to the size of human brains—and the prospect of humanity being wiped out by the technology he helped create. “This stuff will get smarter than us and take over,” says Hinton. “And if you want to know what that feels like, ask a chicken.”\n",
            "Born and raised in England, Hinton comes from a long line of luminaries, with relatives including the mathematician Mary Everest Boole and logician George Boole, whose work is crucial to modern computer science; surgeon James Hinton; and surveyor George Everest, who gave his name to the mountain. \n",
            "The human brain always fascinated Hinton. As a Cambridge University undergraduate, he tried a range of subjects—physiology, physics, philosophy—before graduating with a degree in experimental psychology in 1970. He worked briefly as a carpenter before starting a Ph.D. in AI at the University of Edinburgh, then the U.K.’s only postgraduate program on the subject, in 1972.\n",
            "In the 1970s, artificial intelligence, after failing to live up to its postwar promise, was going through a period of dampened enthusiasm now referred to as the “AI winter.” In this unfashionable field, Hinton pursued an unpopular idea: AI systems known as neural networks, which mimicked the structure of the human brain. His thesis adviser urged him on a weekly basis to change his approach. Each time he replied, “Give me another six months and I’ll prove to you that it works.”\n",
            "Upon completion of his Ph.D., Hinton moved to the U.S., where more funding was available for his research. He published pathbreaking research, for which he was awarded the 2018 Turing Award, in posts at universities across the U.S., before eventually taking a professorship in computer science at the University of Toronto. Toronto has become Hinton’s home base; he travels relatively infrequently because back problems prevent him from sitting down. During car journeys he lies across the back seat; he eats kneeling before a table “like a monk at the altar”; and as he spoke to TIME he swayed gently in front of a head-height camera.\n",
            "In 2012, Hinton and two of his graduate students, Alex Krizhevsky and Ilya Sutskever, now chief scientist at OpenAI, entered ImageNet, a once annual competition in which researchers competed to build the most accurate image-recognition AI systems. They dominated the competition—an emphatic demonstration that neural networks had come of age. Hinton’s persistence had paid off.\n",
            "He and his two students began receiving lucrative offers from big tech companies. They set up a shell company called DNN-research to auction their expertise, and four tech firms—Google, Microsoft, Baidu, and DeepMind—bid tens of millions for the company. After a week, Hinton chose Google over the final bidder, Baidu. In 2013, he joined Google Brain, the cutting-edge machine-learning team he left in May.\n",
            "Hinton has been instrumental in the development and popularization of neural networks, the dominant AI development paradigm that has allowed huge amounts of data to be ingested and processed, leading to advances in image recognition, language understanding, and self-driving cars. His work has potentially hastened the future he fears, in which AI becomes superhuman with disastrous results for humans. In an interview with the New York Times, Hinton said, “I console myself with the normal excuse: If I hadn’t done it, somebody else would have.”\n",
            "Hinton does not know how to prevent superhuman AI systems from taking over. If there’s any hope, he says, it lies with the next generation, noting that he feels too old to continue contributing to research. Many scientists switch to policy work later in their careers, but he declined Google’s offer to take such a role at the company. “I’ve never been very good at or interested in policy issues,” he tells TIME. “I’m a scientist.” \n",
            "Instead, Hinton has spent the past few months sounding the alarm—he can explain the technical details of AI in an accessible way as well as anyone and spends much of his time giving interviews to raise public awareness. He has also spoken with policymakers, including officials in the U.K. Prime Minister’s office, Canadian Prime Minister Justin Trudeau, Executive Vice-President of the European Commission Margrethe Vestager, and U.S. Senators Bernie Sanders and Jon Ossoff.\n",
            "While on a theoretical level he now grasps the risks from AI, Hinton says that his emotions haven’t yet caught up. “The idea that we’re going to be replaced as the apex intelligence is just very hard to get your head around.” \n",
            "But for now, he takes his cues from another relative: his cousin Joan Hinton was one of the only women scientists to work on the Manhattan Project. After the nuclear weapons that she helped to create were dropped on Hiroshima and Nagasaki, she became a peace activist. In 1948 she moved to China, and she spent most of the rest of her life working on dairy farms as an ardent Maoist. Hinton’s own retirement plans are less strident but likewise bucolic: he intends to rediscover carpentry and take long walks.\n",
            "Write to Will Henshall at will.henshall@time.com.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# URL del artículo\n",
        "url = \"https://time.com/collection/time100-ai/6309026/geoffrey-hinton/\"\n",
        "\n",
        "# Realizar una solicitud HTTP para obtener el contenido de la página\n",
        "response = requests.get(url)\n",
        "\n",
        "# Verificar si la solicitud fue exitosa\n",
        "if response.status_code == 200:\n",
        "    # Analizar el contenido HTML de la página con BeautifulSoup\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "    # Encontrar el contenido del artículo (puedes inspeccionar el HTML de la página para encontrar la estructura adecuada)\n",
        "    article_content = soup.find(\"div\", {\"class\": \"article-content\"})\n",
        "\n",
        "    # Extraer el texto del artículo\n",
        "    article_text = \"\"\n",
        "    for paragraph in article_content.find_all(\"p\"):\n",
        "        article_text += paragraph.get_text() + \"\\n\"\n",
        "\n",
        "    # Imprimir el texto del artículo\n",
        "    print(article_text)\n",
        "else:\n",
        "    print(\"Error al obtener la página:\", response.status_code)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Traducción de Texto**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pip install transformers\n",
        "# pip install sentencepiece\n",
        "# pip install sacremoses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "from nltk.tokenize import sent_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "40\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['Over the course of February, Geoffrey Hinton, one of the most influential AI researchers of the past 50 years, had a “slow eureka moment.”\\nHinton, 76, has spent his career trying to build AI systems that model the human brain, mostly in academia before joining Google in 2013.',\n",
              " 'He had always believed that the brain was better than the machines that he and others were building, and that by making them more like the brain, they would improve.',\n",
              " 'But in February, he realized “the digital intelligence we’ve got now may be better than the brain already.',\n",
              " 'It’s just not scaled up quite as big.” \\nDevelopers around the world are currently racing to build the biggest AI systems that they can.',\n",
              " 'Given the current rate at which AI companies are increasing the size of models, it could be less than five years until AI systems have 100 trillion connections—roughly as many as there are between neurons in the human brain.']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "article = sent_tokenize(\n",
        "    article_text\n",
        ")  # Se sacan oraciones para que traduzca todo el articulo ya que es muy larga la cantidad de tokens entregada y toca truncar la data\n",
        "print(len(article))\n",
        "article[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFMarianMTModel.\n",
            "\n",
            "All the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-es.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A lo largo de febrero, Geoffrey Hinton, uno de los investigadores de IA más influyentes de los últimos 50 años, tuvo un “momento eureka lento.” Hinton, de 76 años, ha pasado su carrera tratando de construir sistemas de IA que modelen el cerebro humano, sobre todo en la academia antes de unirse a Google en 2013.\n",
            "Siempre había creído que el cerebro era mejor que las máquinas que él y otros estaban construyendo, y que al hacerlos más parecidos al cerebro, mejorarían.\n",
            "Pero en febrero, se dio cuenta de que “la inteligencia digital que tenemos ahora puede ser mejor que el cerebro ya.\n",
            "Los desarrolladores de todo el mundo están compitiendo actualmente para construir los sistemas de IA más grandes que puedan.\n",
            "Dado el ritmo actual al que las compañías de IA están aumentando el tamaño de los modelos, podría pasar menos de cinco años hasta que los sistemas de IA tengan 100 billones de conexiones, aproximadamente tantas como haya entre las neuronas en el cerebro humano.\n",
            "Alarmado, Hinton dejó su puesto como vicepresidente y compañero de ingeniería en mayo y dio una ráfaga de entrevistas en las que explicó que se había ido para poder hablar libremente sobre los peligros de la IA — y sus lamentos por ayudar a traer esa tecnología a la existencia.\n",
            "Se preocupa por lo que podría pasar una vez que los sistemas de IA alcancen el tamaño de los cerebros humanos — y la perspectiva de que la humanidad sea aniquilada por la tecnología que ayudó a crear.\n",
            "“Esto se hará más inteligente que nosotros y se hará cargo”, dice Hinton.\n",
            "“Y si quieres saber cómo se siente, pregúntale a un pollo”. Nacido y criado en Inglaterra, Hinton proviene de una larga línea de luminarias, con familiares como la matemática Mary Everest Boole y el lógico George Boole, cuyo trabajo es crucial para la ciencia moderna de la computación; el cirujano James Hinton; y el agrimensor George Everest, que dio su nombre a la montaña.\n",
            "El cerebro humano siempre fascinó a Hinton.\n",
            "Como estudiante de la Universidad de Cambridge, probó una serie de asignaturas —fisiología, física, filosofía— antes de graduarse en psicología experimental en 1970.\n",
            "Trabajó brevemente como carpintero antes de comenzar un doctorado en IA en la Universidad de Edimburgo, luego el único programa de postgrado del Reino Unido sobre el tema, en 1972.\n",
            "En la década de 1970, la inteligencia artificial, después de no estar a la altura de su promesa de posguerra, estaba pasando por un período de entusiasmo amortiguado que ahora se conoce como el “invierno AI”. En este campo infashionable, Hinton persiguió una idea impopular: los sistemas de IA conocidos como redes neuronales, que imitaban la estructura del cerebro humano.\n",
            "Su asesor de tesis lo instó semanalmente a cambiar su enfoque.\n",
            "Cada vez que contestaba, “Dame otros seis meses y te demostraré que funciona”. Al terminar su doctorado, Hinton se mudó a los Estados Unidos, donde había más fondos disponibles para su investigación.\n",
            "Publicó investigaciones pioneras, por las que fue galardonado con el Premio Turing 2018, en puestos en universidades de todo Estados Unidos, antes de finalmente tomar una cátedra en ciencias de la computación en la Universidad de Toronto.\n",
            "Toronto se ha convertido en el hogar de Hinton; viaja con relativa poca frecuencia porque los problemas de espalda le impiden sentarse.\n",
            "Durante los viajes en coche se acuesta a través del asiento trasero; come arrodillado ante una mesa “como un monje en el altar”; y mientras hablaba con TIEMPO se balanceó suavemente delante de una cámara de altura de la cabeza.\n",
            "En 2012, Hinton y dos de sus estudiantes de posgrado, Alex Krizhevsky e Ilya Sutskever, ahora científico jefe de OpenAI, entraron en ImageNet, un concurso anual en el que los investigadores compitieron para construir los sistemas de IA de reconocimiento de imágenes más precisos.\n",
            "Ellos dominaron la competencia, una demostración enfática de que las redes neuronales habían alcanzado la mayoría de edad.\n",
            "La persistencia de Hinton había dado sus frutos.\n",
            "Él y sus dos estudiantes comenzaron a recibir ofertas lucrativas de grandes empresas tecnológicas.\n",
            "Crearon una compañía fantasma llamada DNN-investigación para subastar su experiencia, y cuatro empresas de tecnología —Google, Microsoft, Baidu y DeepMind— ofrecen decenas de millones para la compañía.\n",
            "Después de una semana, Hinton eligió Google sobre el postor final, Baidu.\n",
            "En 2013, se unió a Google Brain, el equipo de vanguardia de aprendizaje automático que dejó en mayo.\n",
            "Hinton ha sido instrumental en el desarrollo y popularización de las redes neuronales, el paradigma dominante de desarrollo de IA que ha permitido ingerir y procesar enormes cantidades de datos, lo que ha llevado a avances en el reconocimiento de imágenes, comprensión del lenguaje y autos autoconductores.\n",
            "Su trabajo potencialmente ha acelerado el futuro que teme, en el que la IA se vuelve sobrehumana con resultados desastrosos para los humanos.\n",
            "En una entrevista con el New York Times, Hinton dijo: “Me consuela con la excusa normal: si no lo hubiera hecho, alguien más lo habría hecho”. Hinton no sabe cómo evitar que los sistemas de IA sobrehumanos se hagan cargo.\n",
            "Si hay alguna esperanza, dice, recae en la próxima generación, señalando que se siente demasiado viejo para seguir contribuyendo a la investigación.\n",
            "Muchos científicos cambian al trabajo de políticas más tarde en sus carreras, pero declinó la oferta de Google de tomar tal papel en la empresa.\n",
            "“Nunca he sido muy bueno o interesado en cuestiones de política”, dice a TIME.\n",
            "“Soy un científico”. En cambio, Hinton ha pasado los últimos meses haciendo sonar la alarma, puede explicar los detalles técnicos de la IA de una manera accesible, así como cualquier persona y pasa gran parte de su tiempo dando entrevistas para aumentar la conciencia pública.\n",
            "También ha hablado con los responsables políticos, incluidos funcionarios de la oficina del primer ministro del Reino Unido, el primer ministro canadiense Justin Trudeau, vicepresidente ejecutivo de la Comisión Europea Margrethe Vestager, y Estados Unidos.\n",
            "Los senadores Bernie Sanders y Jon Ossoff.\n",
            "Mientras que en un nivel teórico que ahora capta los riesgos de la IA, Hinton dice que sus emociones todavía no han alcanzado.\n",
            "“La idea de que vamos a ser reemplazados como el ápice de la inteligencia es muy difícil de conseguir su cabeza alrededor.” Pero por ahora, él toma sus señales de otro pariente: su primo Joan Hinton era una de las únicas mujeres científicas que trabajan en el Proyecto Manhattan.\n",
            "Después de que las armas nucleares que ayudó a crear fueron lanzadas sobre Hiroshima y Nagasaki, se convirtió en una activista por la paz.\n",
            "En 1948 se mudó a China, y pasó la mayor parte de su vida trabajando en granjas lecheras como ardiente maoísta.\n",
            "Los propios planes de jubilación de Hinton son menos estridentes pero también bucólicos: pretende redescubrir la carpintería y dar largos paseos.\n",
            "Escriba a Will Henshall a will.henshall@time.com.\n"
          ]
        }
      ],
      "source": [
        "# Se entrena modelo con traductor inglés - español\n",
        "translator = pipeline(\"translation_en_to_es\", model=\"Helsinki-NLP/opus-mt-en-es\")\n",
        "# Se itera sobre todas las oraciones para traducir todo el artículo y no tener que truncarlo o truncarlo lo menor posible.\n",
        "articulo_espanol = []\n",
        "for oracion in article:\n",
        "    articulo_es = translator(\n",
        "        oracion, clean_up_tokenization_spaces=True, truncation=True\n",
        "    )\n",
        "    print(articulo_es[0][\"translation_text\"])\n",
        "    articulo_espanol.append(articulo_es[0][\"translation_text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'A lo largo de febrero, Geoffrey Hinton, uno de los investigadores de IA más influyentes de los últimos 50 años, tuvo un “momento eureka lento.” Hinton, de 76 años, ha pasado su carrera tratando de construir sistemas de IA que modelen el cerebro humano, sobre todo en la academia antes de unirse a Google en 2013. Siempre había creído que el cerebro era mejor que las máquinas que él y otros estaban construyendo, y que al hacerlos más parecidos al cerebro, mejorarían. Pero en febrero, se dio cuenta de que “la inteligencia digital que tenemos ahora puede ser mejor que el cerebro ya. Los desarrolladores de todo el mundo están compitiendo actualmente para construir los sistemas de IA más grandes que puedan. Dado el ritmo actual al que las compañías de IA están aumentando el tamaño de los modelos, podría pasar menos de cinco años hasta que los sistemas de IA tengan 100 billones de conexiones, aproximadamente tantas como haya entre las neuronas en el cerebro humano. Alarmado, Hinton dejó su puesto como vicepresidente y compañero de ingeniería en mayo y dio una ráfaga de entrevistas en las que explicó que se había ido para poder hablar libremente sobre los peligros de la IA — y sus lamentos por ayudar a traer esa tecnología a la existencia. Se preocupa por lo que podría pasar una vez que los sistemas de IA alcancen el tamaño de los cerebros humanos — y la perspectiva de que la humanidad sea aniquilada por la tecnología que ayudó a crear. “Esto se hará más inteligente que nosotros y se hará cargo”, dice Hinton. “Y si quieres saber cómo se siente, pregúntale a un pollo”. Nacido y criado en Inglaterra, Hinton proviene de una larga línea de luminarias, con familiares como la matemática Mary Everest Boole y el lógico George Boole, cuyo trabajo es crucial para la ciencia moderna de la computación; el cirujano James Hinton; y el agrimensor George Everest, que dio su nombre a la montaña. El cerebro humano siempre fascinó a Hinton. Como estudiante de la Universidad de Cambridge, probó una serie de asignaturas —fisiología, física, filosofía— antes de graduarse en psicología experimental en 1970. Trabajó brevemente como carpintero antes de comenzar un doctorado en IA en la Universidad de Edimburgo, luego el único programa de postgrado del Reino Unido sobre el tema, en 1972. En la década de 1970, la inteligencia artificial, después de no estar a la altura de su promesa de posguerra, estaba pasando por un período de entusiasmo amortiguado que ahora se conoce como el “invierno AI”. En este campo infashionable, Hinton persiguió una idea impopular: los sistemas de IA conocidos como redes neuronales, que imitaban la estructura del cerebro humano. Su asesor de tesis lo instó semanalmente a cambiar su enfoque. Cada vez que contestaba, “Dame otros seis meses y te demostraré que funciona”. Al terminar su doctorado, Hinton se mudó a los Estados Unidos, donde había más fondos disponibles para su investigación. Publicó investigaciones pioneras, por las que fue galardonado con el Premio Turing 2018, en puestos en universidades de todo Estados Unidos, antes de finalmente tomar una cátedra en ciencias de la computación en la Universidad de Toronto. Toronto se ha convertido en el hogar de Hinton; viaja con relativa poca frecuencia porque los problemas de espalda le impiden sentarse. Durante los viajes en coche se acuesta a través del asiento trasero; come arrodillado ante una mesa “como un monje en el altar”; y mientras hablaba con TIEMPO se balanceó suavemente delante de una cámara de altura de la cabeza. En 2012, Hinton y dos de sus estudiantes de posgrado, Alex Krizhevsky e Ilya Sutskever, ahora científico jefe de OpenAI, entraron en ImageNet, un concurso anual en el que los investigadores compitieron para construir los sistemas de IA de reconocimiento de imágenes más precisos. Ellos dominaron la competencia, una demostración enfática de que las redes neuronales habían alcanzado la mayoría de edad. La persistencia de Hinton había dado sus frutos. Él y sus dos estudiantes comenzaron a recibir ofertas lucrativas de grandes empresas tecnológicas. Crearon una compañía fantasma llamada DNN-investigación para subastar su experiencia, y cuatro empresas de tecnología —Google, Microsoft, Baidu y DeepMind— ofrecen decenas de millones para la compañía. Después de una semana, Hinton eligió Google sobre el postor final, Baidu. En 2013, se unió a Google Brain, el equipo de vanguardia de aprendizaje automático que dejó en mayo. Hinton ha sido instrumental en el desarrollo y popularización de las redes neuronales, el paradigma dominante de desarrollo de IA que ha permitido ingerir y procesar enormes cantidades de datos, lo que ha llevado a avances en el reconocimiento de imágenes, comprensión del lenguaje y autos autoconductores. Su trabajo potencialmente ha acelerado el futuro que teme, en el que la IA se vuelve sobrehumana con resultados desastrosos para los humanos. En una entrevista con el New York Times, Hinton dijo: “Me consuela con la excusa normal: si no lo hubiera hecho, alguien más lo habría hecho”. Hinton no sabe cómo evitar que los sistemas de IA sobrehumanos se hagan cargo. Si hay alguna esperanza, dice, recae en la próxima generación, señalando que se siente demasiado viejo para seguir contribuyendo a la investigación. Muchos científicos cambian al trabajo de políticas más tarde en sus carreras, pero declinó la oferta de Google de tomar tal papel en la empresa. “Nunca he sido muy bueno o interesado en cuestiones de política”, dice a TIME. “Soy un científico”. En cambio, Hinton ha pasado los últimos meses haciendo sonar la alarma, puede explicar los detalles técnicos de la IA de una manera accesible, así como cualquier persona y pasa gran parte de su tiempo dando entrevistas para aumentar la conciencia pública. También ha hablado con los responsables políticos, incluidos funcionarios de la oficina del primer ministro del Reino Unido, el primer ministro canadiense Justin Trudeau, vicepresidente ejecutivo de la Comisión Europea Margrethe Vestager, y Estados Unidos. Los senadores Bernie Sanders y Jon Ossoff. Mientras que en un nivel teórico que ahora capta los riesgos de la IA, Hinton dice que sus emociones todavía no han alcanzado. “La idea de que vamos a ser reemplazados como el ápice de la inteligencia es muy difícil de conseguir su cabeza alrededor.” Pero por ahora, él toma sus señales de otro pariente: su primo Joan Hinton era una de las únicas mujeres científicas que trabajan en el Proyecto Manhattan. Después de que las armas nucleares que ayudó a crear fueron lanzadas sobre Hiroshima y Nagasaki, se convirtió en una activista por la paz. En 1948 se mudó a China, y pasó la mayor parte de su vida trabajando en granjas lecheras como ardiente maoísta. Los propios planes de jubilación de Hinton son menos estridentes pero también bucólicos: pretende redescubrir la carpintería y dar largos paseos. Escriba a Will Henshall a will.henshall@time.com.'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "articulo_espanol_texto_plano = \" \".join(articulo_espanol)\n",
        "articulo_espanol_texto_plano"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se traduce la pregunta solicitada para poder ingresarla al modelo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "¿Cómo está Geoffrey Hinton?\n"
          ]
        }
      ],
      "source": [
        "question = \"How is Geoffrey Hinton?\"\n",
        "pregunta_es = translator(question, clean_up_tokenization_spaces=True, truncation=True)\n",
        "print(pregunta_es[0][\"translation_text\"])\n",
        "pregunta_espanol = pregunta_es[0][\"translation_text\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Debido a que la traducción no está englobando el 100% de lo que quiere decir la palabra en inglés se empleará traducción por humano en este caso para poder dar respuesta\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "pregunta_espanol_humano = \"¿Cómo es Geoffrey Hinton?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Question and Answering**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Debido a que tenemos dos preguntas (traducida por humano y por máquina), ambas serán incluidas en la prgeunta para conocer qué respuesta nos genera el modelo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Respuesta a pregunta por traducción por computador\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "StIrHeBAB07H"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Downloading (…)lve/main/config.json: 100%|██████████| 473/473 [00:00<?, ?B/s] \n",
            "c:\\Users\\cande\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:137: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\cande\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n",
            "Downloading model.safetensors: 100%|██████████| 261M/261M [00:43<00:00, 5.98MB/s] \n",
            "All PyTorch model weights were used when initializing TFDistilBertForQuestionAnswering.\n",
            "\n",
            "All the weights of TFDistilBertForQuestionAnswering were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForQuestionAnswering for predictions without further training.\n",
            "Downloading (…)okenizer_config.json: 100%|██████████| 29.0/29.0 [00:00<?, ?B/s]\n",
            "Downloading (…)solve/main/vocab.txt: 100%|██████████| 213k/213k [00:00<00:00, 11.4MB/s]\n",
            "Downloading (…)/main/tokenizer.json: 100%|██████████| 436k/436k [00:00<00:00, 1.90MB/s]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>score</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.423527</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>A lo largo de febrero</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      score  start  end                 answer\n",
              "0  0.423527      0   21  A lo largo de febrero"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reader = pipeline(\"question-answering\")\n",
        "respuesta = reader(question=pregunta_espanol, context=articulo_espanol_texto_plano)\n",
        "pd.DataFrame([respuesta])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1duCY3NVFaAH"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>score</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.761458</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>A lo largo de febrero</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      score  start  end                 answer\n",
              "0  0.761458      0   21  A lo largo de febrero"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "respuesta_h = reader(\n",
        "    question=pregunta_espanol_humano, context=articulo_espanol_texto_plano\n",
        ")\n",
        "pd.DataFrame([respuesta_h])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se muestra que a pesar de ser distintas las preguntas, el modelo genera la misma respuesta en ambas ocasiones.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusiones\n",
        "\n",
        "El modelo pudo realizar la traducción tanto de la pregunta como del texto y finalmente respondió las preguntas realizadas aunque no haya sido un 100% acertada."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPQDd+VMwtpkPdp8wqHP1S4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
