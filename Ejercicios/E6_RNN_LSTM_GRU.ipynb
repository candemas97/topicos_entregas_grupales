{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUgBjMmm0YAx"
      },
      "source": [
        "# Exercise 6\n",
        "\n",
        "## Predict rating using LSTM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iXkKZ4Kf0YAz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Vppi3Q6C0YA0"
      },
      "outputs": [],
      "source": [
        "dataTraining = pd.read_csv('https://github.com/sergiomora03/AdvancedTopicsAnalytics/raw/main/datasets/dataTraining.zip', encoding='UTF-8', index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jEfDJEWx0YA1"
      },
      "outputs": [],
      "source": [
        "plots = dataTraining['plot']\n",
        "y = (dataTraining['rating'] >= dataTraining['rating'].mean()).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HQ8i4Hq0YA1",
        "outputId": "11ef093e-3ec9-4286-b482-2e2f4670167f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3107    most is the story of a single father who takes...\n",
              "900     a serial killer decides to teach the secrets o...\n",
              "6724    in sweden ,  a female blackmailer with a disfi...\n",
              "4704    in a friday afternoon in new york ,  the presi...\n",
              "2582    in los angeles ,  the editor of a publishing h...\n",
              "                              ...                        \n",
              "8417    \" our marriage ,  their wedding .  \"  it ' s l...\n",
              "1592    the wandering barbarian ,  conan ,  alongside ...\n",
              "1723    like a tale spun by scheherazade ,  kismet fol...\n",
              "7605    mrs .  brisby ,  a widowed mouse ,  lives in a...\n",
              "215     tinker bell journey far north of never land to...\n",
              "Name: plot, Length: 7895, dtype: object"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9duKIhOA0YA2",
        "outputId": "4e1bcc80-a5e9-4d90-cab6-28f64f8a5df5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3107    1\n",
              "900     0\n",
              "6724    1\n",
              "4704    1\n",
              "2582    1\n",
              "       ..\n",
              "8417    0\n",
              "1592    0\n",
              "1723    0\n",
              "7605    1\n",
              "215     1\n",
              "Name: rating, Length: 7895, dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUmsQHxM0YA2"
      },
      "source": [
        "# Exercise 6.1\n",
        "\n",
        "- Remove stopwords\n",
        "- Lowercase\n",
        "- split the text in words\n",
        "- pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nIVx7kg0YA3",
        "outputId": "2857bd79-4fec-45a9-ce77-350d0123a267"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.13.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ],
      "source": [
        "pip install nltk keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7Xv5GpSCQbv",
        "outputId": "238711ee-1d74-4c50-aa90-139e79d8bbfb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X: (7895, 850)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Descarga lista de stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Preprocesamiento de texto\n",
        "def preprocess_text(text):\n",
        "    # Tokenización (split the text into words)\n",
        "    words = text.split()\n",
        "\n",
        "    # Elimina stopwords y se convierte a minúsculas\n",
        "    words = [word.lower() for word in words if word.lower() not in stop_words]\n",
        "\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Aplicar preprocesamiento a los plots\n",
        "plots = plots.apply(preprocess_text)\n",
        "\n",
        "# Tokenización y secuencia\n",
        "max_words = 1000000  # Número máximo de palabras a considerar en el vocabulario\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(plots)\n",
        "sequences = tokenizer.texts_to_sequences(plots)\n",
        "max_sequence_length = max([len(seq) for seq in sequences])\n",
        "\n",
        "# Padding\n",
        "X = pad_sequences(sequences, maxlen=max_sequence_length)\n",
        "\n",
        "print(\"Shape of X:\", X.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQ14SQaqR8N4"
      },
      "source": [
        "# Exercise 6.2\n",
        "\n",
        "Create a SimpleRNN neural network to predict the rating of a movie\n",
        "\n",
        "Calculate the testing set accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "IQMB76c1hdJr"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, SimpleRNN, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Divición de datos en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iL4pewpBR7nn",
        "outputId": "804a41d9-46ac-4518-c11c-0cdc75239acb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "79/79 [==============================] - 299s 4s/step - loss: 0.7000 - accuracy: 0.5168 - val_loss: 0.6942 - val_accuracy: 0.4771\n",
            "Epoch 2/4\n",
            "79/79 [==============================] - 288s 4s/step - loss: 0.2799 - accuracy: 0.9016 - val_loss: 1.0506 - val_accuracy: 0.4984\n",
            "Epoch 3/4\n",
            "79/79 [==============================] - 299s 4s/step - loss: 0.0132 - accuracy: 0.9978 - val_loss: 1.5084 - val_accuracy: 0.4960\n",
            "Epoch 4/4\n",
            "79/79 [==============================] - 286s 4s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.6533 - val_accuracy: 0.4953\n",
            "50/50 [==============================] - 8s 159ms/step\n",
            "Precisión en el conjunto de prueba: 0.5142495250158328\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Creación de modelo SimpleRNN\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_sequence_length))\n",
        "model.add(SimpleRNN(128,return_sequences=True))\n",
        "model.add(SimpleRNN(64))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile modelo\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Entrenamiento del modelo\n",
        "model.fit(X_train, y_train, epochs=4, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# Evaluación del modelo en conjunto test\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = (y_pred >= 0.5).astype(int)\n",
        "\n",
        "# Calcula la precisión en test\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Precisión en el conjunto de prueba:\", test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ki8anSMk0YA3"
      },
      "source": [
        "# Exercise 6.3\n",
        "\n",
        "Create a LSTM neural network to predict the rating of a movie\n",
        "\n",
        "Calculate the testing set accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfaGPYvw0YA3",
        "outputId": "73d7982a-dc97-44fe-c20f-f6b5777da15f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "40/40 [==============================] - 129s 3s/step - loss: 0.6896 - accuracy: 0.5337 - val_loss: 0.6730 - val_accuracy: 0.5775\n",
            "Epoch 2/5\n",
            "40/40 [==============================] - 125s 3s/step - loss: 0.5983 - accuracy: 0.7142 - val_loss: 0.6601 - val_accuracy: 0.5870\n",
            "Epoch 3/5\n",
            "40/40 [==============================] - 143s 4s/step - loss: 0.3835 - accuracy: 0.8747 - val_loss: 0.7110 - val_accuracy: 0.6218\n",
            "Epoch 4/5\n",
            "40/40 [==============================] - 126s 3s/step - loss: 0.1527 - accuracy: 0.9495 - val_loss: 0.9557 - val_accuracy: 0.6234\n",
            "Epoch 5/5\n",
            "40/40 [==============================] - 127s 3s/step - loss: 0.0458 - accuracy: 0.9897 - val_loss: 1.2645 - val_accuracy: 0.6163\n",
            "50/50 [==============================] - 6s 113ms/step\n",
            "Precisión en el conjunto de prueba: 0.5959468017732742\n"
          ]
        }
      ],
      "source": [
        "from keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "# Creación de modelo LSTM\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=max_words, output_dim=64, input_length=max_sequence_length))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compila el modelo\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Entrena el modelo\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# Evalua el modelo en test\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = (y_pred >= 0.5).astype(int)\n",
        "\n",
        "# Calcula la precisión en test\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Precisión en el conjunto de prueba:\", test_accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3V3dPxvORw6T"
      },
      "source": [
        "# Exercise 6.4\n",
        "\n",
        "Create a GRU neural network to predict the rating of a movie\n",
        "\n",
        "Calculate the testing set accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLjL9dMtRwVJ",
        "outputId": "01b643c7-eb7b-4b20-fecc-ae6250ef5104"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "79/79 [==============================] - 78s 959ms/step - loss: 0.6906 - accuracy: 0.5279 - val_loss: 0.6855 - val_accuracy: 0.5301\n",
            "Epoch 2/5\n",
            "79/79 [==============================] - 74s 941ms/step - loss: 0.5407 - accuracy: 0.7401 - val_loss: 0.7555 - val_accuracy: 0.5736\n",
            "Epoch 3/5\n",
            "79/79 [==============================] - 74s 938ms/step - loss: 0.2708 - accuracy: 0.8913 - val_loss: 0.9753 - val_accuracy: 0.5657\n",
            "Epoch 4/5\n",
            "79/79 [==============================] - 74s 941ms/step - loss: 0.0844 - accuracy: 0.9739 - val_loss: 1.4852 - val_accuracy: 0.5712\n",
            "Epoch 5/5\n",
            "79/79 [==============================] - 74s 936ms/step - loss: 0.0203 - accuracy: 0.9943 - val_loss: 2.1655 - val_accuracy: 0.5783\n",
            "50/50 [==============================] - 5s 105ms/step\n",
            "Precisión en el conjunto de prueba: 0.5503483217226093\n"
          ]
        }
      ],
      "source": [
        "from keras.layers import Embedding, GRU, Dense\n",
        "\n",
        "# Creación de modelo GRU\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_sequence_length))\n",
        "model.add(GRU(128))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compila modelo\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Entrena el modelo\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# Evalua el modelo en test\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = (y_pred >= 0.5).astype(int)\n",
        "\n",
        "# Calcular la precisión en test\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Precisión en el conjunto de prueba:\", test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcV-k1cfNfYc"
      },
      "source": [
        "# **Conclusiones**\n",
        "\n",
        "En las tres redes neuronales se probaron diferentes combinaciones de parámetros como: número de neuronas, agregar capas adicionales y batch_size.\n",
        "\n",
        "\n",
        "*   Únicamente en la red RNN funcionó agregar otra capa de 64 neuronas a la capa inicial de 128, en las otras, disminuía el resultado de las métricas.\n",
        "*   Los batch_size que mejor funcionaron fueron de 128 y 64.\n",
        "*   Agregar más épocas no hacía la diferencia en el resultado obtenido.\n",
        "\n",
        "\n",
        "\n",
        "Los resultados de las 3 redes no superan el 0.6 a pesar de hacer varias pruebas con cambios y combinaciones en los parámetros.\n",
        "\n",
        "La red que mejores resultados tuvo fue la LSTM, seguido por la GRU.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
